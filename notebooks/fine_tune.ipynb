{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning GPT-2 for Sentiment Analysis\n",
    "\n",
    "This guide demonstrates how to fine-tune a pre-trained GPT-2 model for sentiment classification using the Hugging Face `transformers` library. The process involves:\n",
    "\n",
    "1. **Loading and Tokenizing Data**:\n",
    "    - We utilize the `mteb/tweet_sentiment_extraction` dataset, which contains tweets labeled for sentiment analysis.\n",
    "    - The dataset is tokenized using GPT-2's tokenizer, with a special configuration to handle padding by using the `eos_token` as the `pad_token`, ensuring the model treats padding appropriately during training.\n",
    "2. **Model Setup**:\n",
    "    - GPT-2 is adapted for sequence classification by adding a classification head with three sentiment labels (positive, neutral, negative).\n",
    "    - The model is configured to use Apple Silicon's Metal Performance Shaders (MPS) for GPU acceleration if available, enhancing training performance on M1/M2 Macs.\n",
    "3. **Training Configuration**:\n",
    "    - We define training arguments including the number of epochs, batch size, learning rate, and strategies for logging, evaluation, and checkpoint saving.\n",
    "    - A custom `compute_metrics` function is implemented to evaluate the model's performance using accuracy, F1 score (weighted for class imbalance), and AUC-ROC (One-vs-Rest) metrics.\n",
    "4. **Model Training**:\n",
    "    - The `Trainer` class is used to manage the training loop, applying the defined configuration and metrics.\n",
    "    - A subset of the dataset is used for quick iteration and testing, allowing the model to be trained and evaluated efficiently.\n",
    "5. **Evaluation**:\n",
    "    - After training, the modelâ€™s performance is assessed on a test set. The metrics computed provide insights into the modelâ€™s accuracy, its balance between precision and recall (F1 score), and its ability to distinguish between different sentiment classes (AUC-ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/dev/llm_sandbox/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset, instantiate tokenizer and LLM\n",
    "dataset = load_dataset(\"mteb/tweet_sentiment_extraction\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(examples):\n",
    "   return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device to \"mps\" (Metal Performance Shaders) if available, which allows\n",
    "# PyTorch to leverage the GPU on an Apple Silicon Mac (e.g., M1, M2 chip).\n",
    "# If MPS is not available, default to using the CPU.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].select(range(1000))  # Select a smaller subset for training\n",
    "small_test_dataset = tokenized_datasets[\"test\"].select(range(200))  # Select an even smaller subset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cb774db0d1', 'text': ' I`d have responded, if I were going', 'label': 1, 'label_text': 'neutral'}\n",
      "{'id': '549e992a42', 'text': ' Sooo SAD I will miss you here in San Diego!!!', 'label': 0, 'label_text': 'negative'}\n",
      "{'id': '088c60f138', 'text': 'my boss is bullying me...', 'label': 0, 'label_text': 'negative'}\n",
      "{'id': '9642c003ef', 'text': ' what interview! leave me alone', 'label': 0, 'label_text': 'negative'}\n",
      "{'id': '358bd9e861', 'text': ' Sons of ****, why couldn`t they put them on the releases we already bought', 'label': 0, 'label_text': 'negative'}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few examples in the dataset\n",
    "for i in range(5):\n",
    "    print(dataset[\"train\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cb774db0d1', 'text': ' I`d have responded, if I were going', 'label': 1, 'label_text': 'neutral', 'input_ids': [314, 63, 67, 423, 7082, 11, 611, 314, 547, 1016, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'id': '549e992a42', 'text': ' Sooo SAD I will miss you here in San Diego!!!', 'label': 0, 'label_text': 'negative', 'input_ids': [1406, 2238, 311, 2885, 314, 481, 2051, 345, 994, 287, 2986, 9500, 10185, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'id': '088c60f138', 'text': 'my boss is bullying me...', 'label': 0, 'label_text': 'negative', 'input_ids': [1820, 6478, 318, 20714, 502, 986, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'id': '9642c003ef', 'text': ' what interview! leave me alone', 'label': 0, 'label_text': 'negative', 'input_ids': [644, 2720, 0, 2666, 502, 3436, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'id': '358bd9e861', 'text': ' Sons of ****, why couldn`t they put them on the releases we already bought', 'label': 0, 'label_text': 'negative', 'input_ids': [27989, 286, 25998, 11, 1521, 3521, 63, 83, 484, 1234, 606, 319, 262, 10050, 356, 1541, 5839, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the tokenization of a few examples\n",
    "for i in range(5):\n",
    "    print(tokenized_datasets[\"train\"][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I`d have responded, if I were going<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Check if padding and truncation are applied correctly\n",
    "print(tokenizer.decode(tokenized_datasets[\"train\"][0][\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT-2 doesn't have a padding token defined by default, which is necessary when you're using a batch size greater than 1. \n",
    "# To resolve this, we need to define a padding token for the tokenizer.\n",
    "\n",
    "# Set the padding token  to be the same as the eos_token (End of Sequence token).\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Update the model to be aware of which token represents padding in the input sequences\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Set the padding token.  Using the eos_token marks the end of meaningful input and fills in padding spaces.\n",
    "tokenizer.pad_token = tokenizer.eos_token  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Convert logits to probabilities\n",
    "    probs = F.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    # Convert logits to predicted class indices\n",
    "    predictions = np.argmax(probs, axis=-1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # Calculate F1 score (weighted to handle class imbalance)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "    # Calculate AUC (One-vs-Rest for multi-class classification)\n",
    "    auc = roc_auc_score(labels, probs, multi_class='ovr', average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/dev/llm_sandbox/.venv/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='../output',          # Output directory for model checkpoints and logs\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=4,   # Batch size for training\n",
    "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
    "    warmup_steps=500,                # Number of steps to perform learning rate warmup\n",
    "    weight_decay=0.01,               # Strength of weight decay\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,                # Log every 10 steps\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",           # Save checkpoints after each epoch\n",
    "    learning_rate=5e-5               # Learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a744b339dd814fdaab6e0e5b841955d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3404, 'grad_norm': 97.77446746826172, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}\n",
      "{'loss': 3.492, 'grad_norm': 231.92886352539062, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.08}\n",
      "{'loss': 3.049, 'grad_norm': 231.93826293945312, 'learning_rate': 3e-06, 'epoch': 0.12}\n",
      "{'loss': 2.792, 'grad_norm': 162.41400146484375, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.16}\n",
      "{'loss': 2.5212, 'grad_norm': 103.83672332763672, 'learning_rate': 5e-06, 'epoch': 0.2}\n",
      "{'loss': 2.1856, 'grad_norm': 80.27428436279297, 'learning_rate': 6e-06, 'epoch': 0.24}\n",
      "{'loss': 2.098, 'grad_norm': 156.78529357910156, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.28}\n",
      "{'loss': 1.4273, 'grad_norm': 41.621849060058594, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.32}\n",
      "{'loss': 1.326, 'grad_norm': 46.01503372192383, 'learning_rate': 9e-06, 'epoch': 0.36}\n",
      "{'loss': 1.1411, 'grad_norm': 31.84248924255371, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.4985, 'grad_norm': 90.46574401855469, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.44}\n",
      "{'loss': 1.1483, 'grad_norm': 67.55772399902344, 'learning_rate': 1.2e-05, 'epoch': 0.48}\n",
      "{'loss': 1.0869, 'grad_norm': 45.17605972290039, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.52}\n",
      "{'loss': 1.1797, 'grad_norm': 72.64209747314453, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.56}\n",
      "{'loss': 1.2793, 'grad_norm': 42.33586120605469, 'learning_rate': 1.5e-05, 'epoch': 0.6}\n",
      "{'loss': 1.2094, 'grad_norm': 107.10466003417969, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.64}\n",
      "{'loss': 1.1177, 'grad_norm': 39.39949417114258, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.68}\n",
      "{'loss': 0.9771, 'grad_norm': 17.77010726928711, 'learning_rate': 1.8e-05, 'epoch': 0.72}\n",
      "{'loss': 1.0929, 'grad_norm': 19.76796531677246, 'learning_rate': 1.9e-05, 'epoch': 0.76}\n",
      "{'loss': 1.0257, 'grad_norm': 20.165454864501953, 'learning_rate': 2e-05, 'epoch': 0.8}\n",
      "{'loss': 1.0492, 'grad_norm': 33.22282028198242, 'learning_rate': 2.1e-05, 'epoch': 0.84}\n",
      "{'loss': 1.0389, 'grad_norm': 18.090259552001953, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.88}\n",
      "{'loss': 0.9292, 'grad_norm': 19.990692138671875, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.92}\n",
      "{'loss': 1.0315, 'grad_norm': 28.194917678833008, 'learning_rate': 2.4e-05, 'epoch': 0.96}\n",
      "{'loss': 0.8998, 'grad_norm': 38.920894622802734, 'learning_rate': 2.5e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b758c1a3139745c19184c3b178fb1412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2688579559326172, 'eval_accuracy': 0.405, 'eval_f1': 0.32578785514713887, 'eval_auc': 0.7050442672888715, 'eval_runtime': 4.3264, 'eval_samples_per_second': 46.228, 'eval_steps_per_second': 11.557, 'epoch': 1.0}\n",
      "{'loss': 1.0369, 'grad_norm': 41.403263092041016, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.04}\n",
      "{'loss': 1.0068, 'grad_norm': 25.508134841918945, 'learning_rate': 2.7000000000000002e-05, 'epoch': 1.08}\n",
      "{'loss': 0.8381, 'grad_norm': 13.556118965148926, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.12}\n",
      "{'loss': 0.8538, 'grad_norm': 26.07984161376953, 'learning_rate': 2.9e-05, 'epoch': 1.16}\n",
      "{'loss': 0.9212, 'grad_norm': 18.82402801513672, 'learning_rate': 3e-05, 'epoch': 1.2}\n",
      "{'loss': 1.065, 'grad_norm': 92.01287078857422, 'learning_rate': 3.1e-05, 'epoch': 1.24}\n",
      "{'loss': 0.9027, 'grad_norm': 23.44768714904785, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.28}\n",
      "{'loss': 0.7682, 'grad_norm': 4.753272533416748, 'learning_rate': 3.3e-05, 'epoch': 1.32}\n",
      "{'loss': 1.3575, 'grad_norm': 10.01622486114502, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.36}\n",
      "{'loss': 0.6467, 'grad_norm': 19.97635841369629, 'learning_rate': 3.5e-05, 'epoch': 1.4}\n",
      "{'loss': 0.6686, 'grad_norm': 28.3454532623291, 'learning_rate': 3.6e-05, 'epoch': 1.44}\n",
      "{'loss': 0.9447, 'grad_norm': 15.464741706848145, 'learning_rate': 3.7e-05, 'epoch': 1.48}\n",
      "{'loss': 0.9171, 'grad_norm': 31.887264251708984, 'learning_rate': 3.8e-05, 'epoch': 1.52}\n",
      "{'loss': 0.858, 'grad_norm': 15.174622535705566, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.56}\n",
      "{'loss': 0.6028, 'grad_norm': 17.7902889251709, 'learning_rate': 4e-05, 'epoch': 1.6}\n",
      "{'loss': 0.6154, 'grad_norm': 12.640478134155273, 'learning_rate': 4.1e-05, 'epoch': 1.64}\n",
      "{'loss': 1.0052, 'grad_norm': 75.06603240966797, 'learning_rate': 4.2e-05, 'epoch': 1.68}\n",
      "{'loss': 0.4619, 'grad_norm': 13.290149688720703, 'learning_rate': 4.3e-05, 'epoch': 1.72}\n",
      "{'loss': 0.9018, 'grad_norm': 62.926856994628906, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.76}\n",
      "{'loss': 0.6956, 'grad_norm': 54.00425338745117, 'learning_rate': 4.5e-05, 'epoch': 1.8}\n",
      "{'loss': 0.7567, 'grad_norm': 38.305118560791016, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.84}\n",
      "{'loss': 0.9959, 'grad_norm': 72.6214370727539, 'learning_rate': 4.7e-05, 'epoch': 1.88}\n",
      "{'loss': 0.6531, 'grad_norm': 30.624006271362305, 'learning_rate': 4.8e-05, 'epoch': 1.92}\n",
      "{'loss': 1.119, 'grad_norm': 67.40029907226562, 'learning_rate': 4.9e-05, 'epoch': 1.96}\n",
      "{'loss': 0.8983, 'grad_norm': 37.71358871459961, 'learning_rate': 5e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ec4a9415bf4ebbaf451a8d24e0916c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6198831796646118, 'eval_accuracy': 0.755, 'eval_f1': 0.755, 'eval_auc': 0.8857596214919955, 'eval_runtime': 13.3552, 'eval_samples_per_second': 14.975, 'eval_steps_per_second': 3.744, 'epoch': 2.0}\n",
      "{'loss': 0.573, 'grad_norm': 49.29901123046875, 'learning_rate': 4.8e-05, 'epoch': 2.04}\n",
      "{'loss': 0.5306, 'grad_norm': 50.19501876831055, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.08}\n",
      "{'loss': 0.4739, 'grad_norm': 5.950389385223389, 'learning_rate': 4.4000000000000006e-05, 'epoch': 2.12}\n",
      "{'loss': 0.6368, 'grad_norm': 13.032154083251953, 'learning_rate': 4.2e-05, 'epoch': 2.16}\n",
      "{'loss': 0.7921, 'grad_norm': 86.68267822265625, 'learning_rate': 4e-05, 'epoch': 2.2}\n",
      "{'loss': 0.506, 'grad_norm': 18.818553924560547, 'learning_rate': 3.8e-05, 'epoch': 2.24}\n",
      "{'loss': 0.5022, 'grad_norm': 24.89988899230957, 'learning_rate': 3.6e-05, 'epoch': 2.28}\n",
      "{'loss': 0.6122, 'grad_norm': 10.987289428710938, 'learning_rate': 3.4000000000000007e-05, 'epoch': 2.32}\n",
      "{'loss': 0.6347, 'grad_norm': 26.805278778076172, 'learning_rate': 3.2000000000000005e-05, 'epoch': 2.36}\n",
      "{'loss': 0.6266, 'grad_norm': 18.978925704956055, 'learning_rate': 3e-05, 'epoch': 2.4}\n",
      "{'loss': 0.4345, 'grad_norm': 16.489994049072266, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.44}\n",
      "{'loss': 0.3094, 'grad_norm': 16.707136154174805, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.48}\n",
      "{'loss': 0.4304, 'grad_norm': 28.802906036376953, 'learning_rate': 2.4e-05, 'epoch': 2.52}\n",
      "{'loss': 0.3322, 'grad_norm': 48.02254867553711, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.56}\n",
      "{'loss': 0.7247, 'grad_norm': 86.07138061523438, 'learning_rate': 2e-05, 'epoch': 2.6}\n",
      "{'loss': 0.9199, 'grad_norm': 31.622514724731445, 'learning_rate': 1.8e-05, 'epoch': 2.64}\n",
      "{'loss': 0.4765, 'grad_norm': 40.69307327270508, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.68}\n",
      "{'loss': 0.4117, 'grad_norm': 17.758193969726562, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.72}\n",
      "{'loss': 0.4526, 'grad_norm': 26.69331932067871, 'learning_rate': 1.2e-05, 'epoch': 2.76}\n",
      "{'loss': 0.3815, 'grad_norm': 82.18330383300781, 'learning_rate': 1e-05, 'epoch': 2.8}\n",
      "{'loss': 0.5424, 'grad_norm': 71.8719253540039, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.84}\n",
      "{'loss': 0.3642, 'grad_norm': 21.80550193786621, 'learning_rate': 6e-06, 'epoch': 2.88}\n",
      "{'loss': 0.7722, 'grad_norm': 4.3996076583862305, 'learning_rate': 4.000000000000001e-06, 'epoch': 2.92}\n",
      "{'loss': 0.3907, 'grad_norm': 42.633548736572266, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.96}\n",
      "{'loss': 0.8042, 'grad_norm': 29.676502227783203, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e725705c7ab146ac952f542b50a6f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.680131196975708, 'eval_accuracy': 0.755, 'eval_f1': 0.7564746934065115, 'eval_auc': 0.8851832523170653, 'eval_runtime': 6.0848, 'eval_samples_per_second': 32.869, 'eval_steps_per_second': 8.217, 'epoch': 3.0}\n",
      "{'train_runtime': 406.9496, 'train_samples_per_second': 7.372, 'train_steps_per_second': 1.843, 'train_loss': 1.000835683186849, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1963b3d2817b421bb7bc4103faa69036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.680131196975708, 'eval_accuracy': 0.755, 'eval_f1': 0.7564746934065115, 'eval_auc': 0.8851832523170653, 'eval_runtime': 6.9074, 'eval_samples_per_second': 28.954, 'eval_steps_per_second': 7.239, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=small_train_dataset,\n",
    "   eval_dataset=small_test_dataset,\n",
    "   compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Interpreting the Results:\n",
    "\n",
    "- **`eval_loss`:** Indicates how well the model is performing on the evaluation set. A lower loss generally suggests better performance, as it reflects the model's ability to minimize errors in predictions.\n",
    "\n",
    "- **`eval_accuracy`:** Represents the percentage of correct predictions made by the model out of the total predictions. For example, an accuracy of 0.80 means the model correctly predicts the sentiment 80% of the time.\n",
    "\n",
    "- **`eval_f1`:** The F1 score is a measure of a model's accuracy that considers both precision (the proportion of positive identifications that are actually correct) and recall (the proportion of actual positives that were correctly identified). It's especially useful when dealing with imbalanced classes. A higher F1 score indicates a better balance between precision and recall.\n",
    "\n",
    "- **`eval_auc`:** The AUC-ROC score (Area Under the Receiver Operating Characteristic Curve) with One-vs-Rest (OvR) strategy measures the model's ability to distinguish between classes. It evaluates the true positive rate against the false positive rate across different threshold values. A higher AUC-ROC score suggests that the model has a good measure of separability between the classes, meaning it can effectively differentiate between different sentiment classes.\n",
    "\n",
    "- **`epoch`:** Shows the number of training cycles completed. For example, `epoch = 3.0` indicates that the model has been trained over the entire dataset three times.\n",
    "\n",
    "These metrics together provide a comprehensive view of how well the model is performing, offering insights into its accuracy, balance, and ability to distinguish between different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "\n",
    "- Consider increasing training epochs.\n",
    "- Experiment with different hyperparameters.\n",
    "- Add more data or refine the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Using AUC-ROC and F1-Score\n",
    "\n",
    "In this analysis, we compare the performance of three different machine learning modelsâ€”Logistic Regression, Support Vector Machine (SVM), and Random Forestâ€”on a sentiment classification task. Each model is trained on embeddings generated using Word2Vec, a method that converts text into vector representations by capturing the semantic relationships between words.\n",
    "\n",
    "### Steps Involved:\n",
    "1. **Word2Vec Embeddings**: \n",
    "   - We trained a Word2Vec model on the training dataset to generate 100-dimensional word embeddings.\n",
    "   - Sentences in the dataset were split into individual words, and the average of the word embeddings was used to create a fixed-size vector for each sentence.\n",
    "\n",
    "2. **Model Training**:\n",
    "   - Three classifiers were trained using the Word2Vec embeddings: Logistic Regression, SVM (with probability estimates), and Random Forest.\n",
    "   - Each model's performance was evaluated using two key metrics: AUC-ROC (One-vs-Rest) and F1-Score.\n",
    "\n",
    "3. **Evaluation Metrics**:\n",
    "   - **AUC-ROC (OvR)**: This metric measures the modelâ€™s ability to distinguish between different classes. The One-vs-Rest (OvR) strategy was used to handle the multi-class nature of the task.\n",
    "   - **F1-Score**: This score is calculated as the harmonic mean of precision and recall, offering a balanced measure of model performance, especially useful for imbalanced datasets.\n",
    "\n",
    "\n",
    "### Interpretation:\n",
    "- **Logistic Regression**: Provides a baseline for comparison. Although it is simple, it often performs well in scenarios where data is linearly separable.\n",
    "- **SVM**: Known for handling non-linear relationships, this model might perform better if the data is complex and not linearly separable.\n",
    "- **Random Forest**: As an ensemble method, it can capture complex patterns and is less prone to overfitting than individual models.\n",
    "\n",
    "The comparison helps determine if the complexity and computational cost of more sophisticated models like SVM or Random Forest are justified compared to simpler models like Logistic Regression. By evaluating both AUC-ROC and F1-Score, we get a comprehensive understanding of how well each model distinguishes between classes and balances precision and recall. \n",
    "\n",
    "These insights guide the selection of the most appropriate model for deployment, considering the trade-offs between performance, interpretability, and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model on the dataset\n",
    "sentences = [sentence.split() for sentence in small_train_dataset[\"text\"]]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "def word2vec_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        word_vecs = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "        if word_vecs:\n",
    "            embeddings.append(np.mean(word_vecs, axis=0))\n",
    "        else:\n",
    "            embeddings.append(np.zeros(100))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Create Word2Vec embeddings for the training data\n",
    "train_embeddings = word2vec_embeddings(small_train_dataset[\"text\"])\n",
    "test_embeddings = word2vec_embeddings(small_test_dataset[\"text\"])\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "lr.fit(train_embeddings, small_train_dataset[\"label\"])\n",
    "lr_probs = lr.predict_proba(test_embeddings)\n",
    "lr_auc = roc_auc_score(small_test_dataset[\"label\"], lr_probs, multi_class='ovr', average='weighted')\n",
    "\n",
    "# SVM with probability estimates\n",
    "svm = make_pipeline(StandardScaler(), SVC(probability=True))\n",
    "svm.fit(train_embeddings, small_train_dataset[\"label\"])\n",
    "svm_probs = svm.predict_proba(test_embeddings)\n",
    "svm_auc = roc_auc_score(small_test_dataset[\"label\"], svm_probs, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf.fit(train_embeddings, small_train_dataset[\"label\"])\n",
    "rf_probs = rf.predict_proba(test_embeddings)\n",
    "rf_auc = roc_auc_score(small_test_dataset[\"label\"], rf_probs, multi_class='ovr', average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC-ROC OvR: 0.6599149069933241, F1-Score: 0.4895631457145218\n",
      "SVM AUC-ROC OvR: 0.6450256918789293, F1-Score: 0.43086562860867944\n",
      "Random Forest AUC-ROC OvR: 0.5974000421284594, F1-Score: 0.4127470563834201\n"
     ]
    }
   ],
   "source": [
    "# Calculate F1-Score for each model\n",
    "lr_f1 = f1_score(small_test_dataset[\"label\"], lr.predict(test_embeddings), average='weighted')\n",
    "svm_f1 = f1_score(small_test_dataset[\"label\"], svm.predict(test_embeddings), average='weighted')\n",
    "rf_f1 = f1_score(small_test_dataset[\"label\"], rf.predict(test_embeddings), average='weighted')\n",
    "\n",
    "# Print AUC-ROC OvR and F1-Score for each model\n",
    "print(f'Logistic Regression AUC-ROC OvR: {lr_auc}, F1-Score: {lr_f1}')\n",
    "print(f'SVM AUC-ROC OvR: {svm_auc}, F1-Score: {svm_f1}')\n",
    "print(f'Random Forest AUC-ROC OvR: {rf_auc}, F1-Score: {rf_f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec's 100-dimensional word embeddings and the embeddings generated by a transformer model like GPT-2 are fundamentally different in terms of their architecture, contextual awareness, and the type of information they capture. Hereâ€™s a comparison to help understand the differences:\n",
    "\n",
    "### 1. **Contextual Awareness**:\n",
    "   - **Word2Vec**: Generates static embeddings. This means that each word has a single fixed vector representation, regardless of the context in which it appears. For example, the word \"bank\" will have the same embedding whether it's used in the context of a riverbank or a financial institution.\n",
    "   - **Transformers (GPT-2)**: Produce contextual embeddings. The same word can have different embeddings depending on the surrounding words, allowing the model to capture the word's meaning based on the context. For example, \"bank\" would have different embeddings in \"river bank\" versus \"investment bank.\"\n",
    "\n",
    "### 2. **Dimensionality**:\n",
    "   - **Word2Vec**: Typically uses a lower dimensionality (e.g., 100 or 300 dimensions). While lower-dimensional embeddings are easier to compute and use less memory, they may not capture as much nuanced information as higher-dimensional embeddings.\n",
    "   - **Transformers (GPT-2)**: Typically use higher-dimensional embeddings (e.g., 768 dimensions for GPT-2). These embeddings are more expressive, capturing more complex relationships and nuances in the text due to the higher dimensionality and the model's deeper architecture.\n",
    "\n",
    "### 3. **Training Objectives**:\n",
    "   - **Word2Vec**: Is trained using objectives like Skip-Gram or Continuous Bag of Words (CBOW), focusing on predicting words based on their neighbors or vice versa. It captures co-occurrence statistics of words.\n",
    "   - **Transformers (GPT-2)**: Are trained using objectives like next-word prediction (causal language modeling). They use self-attention mechanisms to consider the entire context of a sentence or paragraph to generate embeddings, resulting in richer, contextually-informed representations.\n",
    "\n",
    "### 4. **Use Cases**:\n",
    "   - **Word2Vec**: Often used in simpler NLP tasks where context-specific meaning is less critical, or where computational resources are limited.\n",
    "   - **Transformers (GPT-2)**: Preferred in complex NLP tasks like language generation, contextual understanding, and tasks requiring deep semantic comprehension.\n",
    "\n",
    "### Conclusion:\n",
    "While Word2Vec's 100-dimensional embeddings provide a quick and efficient way to represent words in vector space, they are not directly comparable to the embeddings generated by transformer models like GPT-2. The latter's embeddings are far more sophisticated, capturing richer, context-dependent nuances, which makes them more powerful for many NLP tasks. Therefore, if the goal is to leverage deep contextual understanding and nuanced language features, transformers significantly outperform Word2Vec in most scenarios. However, Word2Vec can still be valuable in scenarios where simplicity and speed are priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
