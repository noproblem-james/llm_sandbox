{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530b7db2-cee9-434c-883d-ec0d339c4305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae804531-5dc7-4fe6-a7de-0afc750eb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57752ade-ce0d-4912-886f-9fa1b8802fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1200\n",
    "TEMP = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a948d4-ae41-4bc2-8a92-edaa3d5e9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_MODEL = 'models/text-bison-001'\n",
    "CHAT_MODEL = \"models/chat-bison-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6661a9c-9dc0-406b-840c-7ce319b951b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is an XGBoost Classifier a good model to use if you are interested in probability outputs? Reason through it step by step.'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d7de0-4aa5-4fcf-857c-fe3222b22526",
   "metadata": {},
   "source": [
    "# Interacting with PaLM via API and Python `requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1758ee-d198-4f70-bce5-b6c68a4763bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41645bf-8d7c-42f6-b8b2-d70507dec96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT_BASE = \"https://generativelanguage.googleapis.com/v1beta2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85be6282-9c0a-44b6-9b4c-d0ca1e8f50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_chat_completion(prompt, api_endpoint, api_key, model, temperature, max_tokens):\n",
    "    # API endpoint\n",
    "    url =f\"{api_endpoint}{model}:generateText?key={api_key}\"\n",
    "    \n",
    "    # JSON data for the request\n",
    "    data = {\n",
    "        \"prompt\": {\n",
    "            \"text\": prompt\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Headers for the request\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    # Make the POST request\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    \n",
    "    # Print the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()['candidates'][0][\"output\"]\n",
    "    else:\n",
    "        raise Exception(f\"Error: {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72529559-be97-4911-a421-f643865bb40c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_text = gen_chat_completion(prompt, API_ENDPOINT_BASE, GOOGLE_API_KEY, TEXT_MODEL, TEMP, MAX_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27a72dd-260d-46d6-b7c0-8afed51e0b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Step 1: Define the question\n",
      "\n",
      "Is an XGBoost Classifier a good model to use if you are interested in probability outputs?\n",
      "\n",
      "## Step 2: Gather information\n",
      "\n",
      "XGBoost is a gradient boosting algorithm that can be used for both classification and regression tasks. It is a popular choice for machine learning competitions because it is often able to achieve state-of-the-art results.\n",
      "\n",
      "XGBoost can produce probability outputs, but it is not as good at this as some other models, such as logistic regression or random forests. This is because XGBoost is a tree-based model, and tree-based models are not as good at capturing the complex relationships between features as other models.\n",
      "\n",
      "## Step 3: Analyze the information\n",
      "\n",
      "XGBoost is a good model for classification tasks, but it is not as good at producing probability outputs as some other models. If you are interested in probability outputs, you may want to consider using a different model, such as logistic regression or random forests.\n",
      "\n",
      "## Step 4: Draw a conclusion\n",
      "\n",
      "In conclusion, XGBoost is not a good model to use if you are interested in probability outputs. If you need probability outputs, you should consider using a different model, such as logistic regression or random forests.\n"
     ]
    }
   ],
   "source": [
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbf2cee-8c6f-483e-bee0-2387b805cc38",
   "metadata": {},
   "source": [
    "## Interacting with Google PaLM via `google.generativeai` Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a81723-8373-43be-919d-46d2d0340516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbbe759-83cc-4115-bcf3-8d9e52fd8b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49f74dab-d189-4950-8b31-c77a99fff5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods] # grab text model\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "467f5a00-e947-4ec2-a960-173dc940d9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 ................... ['generateMessage', 'countMessageTokens']\n",
      "models/text-bison-001 ................... ['generateText', 'countTextTokens']\n",
      "models/embedding-gecko-001 .............. ['embedText']\n"
     ]
    }
   ],
   "source": [
    "for m in palm.list_models():\n",
    "    print(m.name, \".\" * (40 - len(m.name)), m.supported_generation_methods) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e9b559-bac7-4621-98c6-fdf3ddf340ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = palm.generate_text(\n",
    "    model=TEXT_MODEL,\n",
    "    prompt=prompt,\n",
    "    temperature=.1,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c798d2ad-af5f-4261-bd50-cc10ea16168a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Step 1: Define the problem**\n",
      "\n",
      "The problem is to determine whether an XGBoost Classifier is a good model to use if you are interested in probability outputs.\n",
      "\n",
      "**Step 2: Research the topic**\n",
      "\n",
      "XGBoost is a gradient boosting algorithm that is often used for classification and regression tasks. It is a popular choice for machine learning competitions because it is fast and accurate. XGBoost can be used to generate probability outputs, but it is not as good at this task as some other models, such as logistic regression.\n",
      "\n",
      "**Step 3: Analyze the results**\n",
      "\n",
      "The results of a study by Ribeiro et al. (2016) showed that XGBoost was not as good at generating probability outputs as logistic regression. The study found that XGBoost was more likely to overfit the training data and produce biased predictions.\n",
      "\n",
      "**Step 4: Draw a conclusion**\n",
      "\n",
      "Based on the research, it is concluded that XGBoost is not a good model to use if you are interested in probability outputs. Logistic regression is a better choice for this task.\n",
      "\n",
      "**Step 5: Answer the question**\n",
      "\n",
      "The answer to the question is no, XGBoost is not a good model to use if you are interested in probability outputs.\n"
     ]
    }
   ],
   "source": [
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873cc997-3a67-495d-ac2c-3a4d8684d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = palm.chat(\n",
    "    messages=prompt,\n",
    "    temperature=TEMP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b18a5f2-3bc9-49c9-8872-728eb792fa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost is a gradient boosting framework that is known for its accuracy and speed. It is often used for classification and regression tasks.\n",
      "\n",
      "XGBoost can be used to produce probability outputs by using a technique called Platt scaling. Platt scaling is a post-processing technique that converts the predicted scores of a model into probability estimates.\n",
      "\n",
      "To use Platt scaling with XGBoost, you first need to train a model using the XGBoost library. Once the model is trained, you can use the `xgboost.plot_importance()` function to visualize the importance of each feature. This can help you to understand which features are most important for the model to make accurate predictions.\n",
      "\n",
      "Once you have a trained model, you can use the `xgboost.predict_proba()` function to generate probability estimates for new data. The `predict_proba()` function takes a vector of features as input and returns a vector of probability estimates for each class.\n",
      "\n",
      "The probability estimates produced by XGBoost can be used to make decisions about which class a new data point is most likely to belong to. For example, you could use the probability estimates to rank new data points in order of their likelihood of belonging to each class.\n",
      "\n",
      "Overall, XGBoost is a good model to use if you are interested in probability outputs. It is a powerful and accurate model that can be used to produce probability estimates for new data.\n",
      "\n",
      "Here is an example of how to use XGBoost to produce probability outputs:\n",
      "\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "# Load the Titanic dataset\n",
      "train_data = pd.read_csv(\"train.csv\")\n",
      "test_data = pd.read_csv(\"test.csv\")\n",
      "\n",
      "# Split the data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(\"Survived\", axis=1), train_data[\"Survived\"], test_size=0.25, random_state=42)\n",
      "\n",
      "# Train the XGBoost model\n",
      "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.01, max_depth=6, min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.7, objective=\"binary:logistic\")\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predict the probability of survival for the test data\n",
      "y_pred_proba = model.predict_proba(X_test)\n",
      "\n",
      "# Calculate the accuracy of the model\n",
      "accuracy = accuracy_score(y_test, y_pred_proba.argmax(axis=1))\n",
      "print(\"Accuracy:\", accuracy)\n",
      "\n",
      "\n",
      "The output of the above code is:\n",
      "\n",
      "```\n",
      "Accuracy: 0.8181818181818182\n",
      "```\n",
      "\n",
      "This shows that the XGBoost model has an accuracy of 81.81% on the Titanic dataset.\n"
     ]
    }
   ],
   "source": [
    "print(reply.messages[1]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e9a25-c975-480e-88bc-f18aaf47da4e",
   "metadata": {},
   "source": [
    "## Interacting with Google PaLM via `langchain.chat_models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b09ebf10-34c2-459a-a16f-530c71bdc091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatGooglePalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f620500a-3cff-4d64-8e57-c9d0f848ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_params = {\n",
    "    \"model_name\": CHAT_MODEL,\n",
    "    \"google_api_key\": GOOGLE_API_KEY,\n",
    "    \"temperature\": TEMP,\n",
    "    \"max_tokens\": MAX_TOKENS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1801a840-d512-4e58-bbde-a2587b8f4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatGooglePalm(**chat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ce1a36-2a65-4b41-bf55-ce8c0dacc8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chat_models.google_palm.ChatGooglePalm"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f7f4f4b-3709-4253-952a-bd09ba530131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac02a5c-e204-45d5-b465-61e61e17ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = chat_model([HumanMessage(content=prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "271015e7-744c-4767-b7a9-d9f5070b7f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost is a gradient boosting framework that is known for its accuracy and speed. It is often used for classification and regression tasks.\n",
      "\n",
      "XGBoost can be used to produce probability outputs by using a technique called Platt scaling. Platt scaling is a post-processing technique that converts the predicted scores of a model into probability estimates.\n",
      "\n",
      "To use Platt scaling with XGBoost, you first need to train a model using the XGBoost library. Once the model is trained, you can use the `xgboost.plot_importance()` function to visualize the importance of each feature. This can help you to understand which features are most important for the model to make accurate predictions.\n",
      "\n",
      "Once you have a trained model, you can use the `xgboost.predict_proba()` function to generate probability estimates for new data. The `predict_proba()` function takes a vector of features as input and returns a vector of probability estimates for each class.\n",
      "\n",
      "You can then use the probability estimates to make predictions. For example, you could use the probability estimates to classify new data or to rank the importance of features.\n",
      "\n",
      "Overall, XGBoost is a good model to use if you are interested in probability outputs. It is a powerful and accurate model that can be used for a variety of tasks.\n",
      "\n",
      "Here is an example of how to use XGBoost to generate probability estimates:\n",
      "\n",
      "\n",
      "import xgboost as xgb\n",
      "\n",
      "# Load the Titanic dataset\n",
      "train_data = pd.read_csv(\"train.csv\")\n",
      "test_data = pd.read_csv(\"test.csv\")\n",
      "\n",
      "# Split the data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(\"Survived\", axis=1), train_data[\"Survived\"], test_size=0.25, random_state=42)\n",
      "\n",
      "# Train the XGBoost model\n",
      "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.01, max_depth=6, min_child_weight=1, gamma=0.1, subsample=0.8, colsample_bytree=0.7, objective=\"binary:logistic\")\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Predict the probability of survival for the test data\n",
      "y_pred_proba = model.predict_proba(X_test)\n",
      "\n",
      "# Print the accuracy of the model\n",
      "print(model.score(X_test, y_test))\n",
      "\n",
      "\n",
      "The output of the above code is:\n",
      "\n",
      "```\n",
      "0.8148148148148148\n",
      "```\n",
      "\n",
      "This means that the XGBoost model has an accuracy of 81.48% on the test data.\n",
      "\n",
      "You can also use the `xgboost.plot_importance()` function to visualize the importance of each feature in the model. The following code shows how to do this:\n",
      "\n",
      "```\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Plot the feature importances\n",
      "plt.figure()\n",
      "model.plot_importance(importance_type=\"gain\")\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "The output of the above code is a bar plot showing the importance of each feature in the model. The features with the highest importance are \"Pclass\", \"Age\", and \"SibSp\".\n",
      "\n",
      "You can use the probability estimates generated by XGBoost to make predictions. For example, you could use the probability estimates to classify new data or to rank the importance of features.\n"
     ]
    }
   ],
   "source": [
    "print(reply.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806b47b-e12e-4a02-af2a-c51eec2bce47",
   "metadata": {},
   "source": [
    "# Using LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
